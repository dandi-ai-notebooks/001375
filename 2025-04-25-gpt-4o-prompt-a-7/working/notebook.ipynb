{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdef908",
   "metadata": {},
   "source": [
    "# Exploring Dandiset 001375: Septum GABA Disruption with DREADDs\n",
    "\n",
    "**Disclaimer**: This notebook was AI-generated and has not been fully verified. Users should exercise caution when interpreting the code or results presented here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6a7580",
   "metadata": {},
   "source": [
    "## Overview of Dandiset 001375\n",
    "Dandiset 001375, titled \"Septum GABA disruption with DREADDs,\" is a pilot study exploring the effects of disrupting septal GABAergic activity on hippocampal and neocortical function. The Dandiset is openly accessible and is licensed under CC-BY-4.0.\n",
    "\n",
    "More information can be found on the [Dandiset page](https://dandiarchive.org/dandiset/001375)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d458467f",
   "metadata": {},
   "source": [
    "## Notebook Objectives\n",
    "This notebook will guide the user through:\n",
    "1. Connecting to the DANDI API and loading the Dandiset metadata.\n",
    "2. Accessing and exploring NWB files within the Dandiset.\n",
    "3. Visualizing data from the NWB files.\n",
    "4. Providing insights and directions for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c93d321",
   "metadata": {},
   "source": [
    "## Required Packages\n",
    "This notebook assumes the following packages are installed: `dandi`, `pynwb`, `h5py`, `remfile`, and `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7394d0a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T11:15:22.108475Z",
     "iopub.status.busy": "2025-04-25T11:15:22.108179Z",
     "iopub.status.idle": "2025-04-25T11:15:23.818238Z",
     "shell.execute_reply": "2025-04-25T11:15:23.817686Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "import pynwb\n",
    "import h5py\n",
    "import remfile\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0e392a",
   "metadata": {},
   "source": [
    "## Loading the Dandiset\n",
    "\n",
    "\n",
    "Connect to DANDI archive\n",
    "client = DandiAPIClient()\n",
    "\n",
    "Retrieve the Dandiset\n",
    "dandiset = client.get_dandiset(\"001375\")\n",
    "\n",
    "Print basic information about the Dandiset\n",
    "metadata = dandiset.get_raw_metadata()\n",
    "print(f\"Dandiset name: {metadata.get('name', 'N/A')}\")\n",
    "print(f\"Dandiset URL: {metadata.get('url', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e95db55",
   "metadata": {},
   "source": [
    "### Listing the Assets\n",
    "The assets in the Dandiset can be listed to identify files of interest.\n",
    "\n",
    "\n",
    "List the assets in the Dandiset\n",
    "assets = list(dandiset.get_assets())\n",
    "print(f\"Found {len(assets)} assets in the dataset\")\n",
    "print(\"First 5 assets:\")\n",
    "for asset in assets[:5]:\n",
    "    print(f\"- {asset.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08008f8b",
   "metadata": {},
   "source": [
    "## Loading an NWB File\n",
    "We'll load one of the NWB files and examine its contents. The file path chosen is `sub-MS13B/sub-MS13B_ses-20240725T190000_ecephys.nwb`. The asset's URL can be explored further on [NeuroSift](https://neurosift.app/nwb?url=https://api.dandiarchive.org/api/assets/ce525828-8534-4b56-9e47-d2a34d1aa897/download/&dandisetId=001375&dandisetVersion=draft)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2380f9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T11:15:23.820485Z",
     "iopub.status.busy": "2025-04-25T11:15:23.820057Z",
     "iopub.status.idle": "2025-04-25T11:15:24.526652Z",
     "shell.execute_reply": "2025-04-25T11:15:24.526156Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/hdmf/spec/namespace.py:535: UserWarning: Ignoring cached namespace 'core' version 2.8.0 because version 2.7.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session description: mouse running laps in virtual hallway\n",
      "Session start time: 2024-07-25 19:00:00-07:00\n",
      "File creation date: [datetime.datetime(2025, 4, 5, 16, 50, 15, 663983, tzinfo=tzoffset(None, -25200))]\n"
     ]
    }
   ],
   "source": [
    "# Load the NWB file\n",
    "url = \"https://api.dandiarchive.org/api/assets/ce525828-8534-4b56-9e47-d2a34d1aa897/download/\"\n",
    "remote_file = remfile.File(url)\n",
    "h5_file = h5py.File(remote_file)\n",
    "io = pynwb.NWBHDF5IO(file=h5_file, mode='r')\n",
    "nwb = io.read()\n",
    "\n",
    "# Display basic session information\n",
    "print(f\"Session description: {nwb.session_description}\")\n",
    "print(f\"Session start time: {nwb.session_start_time}\")\n",
    "print(f\"File creation date: {nwb.file_create_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd46c4d",
   "metadata": {},
   "source": [
    "## Visualizing Data\n",
    "Here, we will visualize some data from the loaded NWB file.\n",
    "\n",
    "\n",
    "Plot a subset of time series data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series.data[:1000, 0], label='Sample Data')\n",
    "plt.title('Time Series Sample Plot')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687add32",
   "metadata": {},
   "source": [
    "## Summary and Future Directions\n",
    "This notebook introduced the Dandiset and guided you through the process of accessing and visualizing its contents. Future analysis can focus on specific experiments and advanced data processing techniques."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
